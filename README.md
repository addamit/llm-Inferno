# llm-Inferno
dive into LLM inference, performance optimization, and the mysterious ways of CPU/GPU acceleration.
